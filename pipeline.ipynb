{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRI - Pipeline\n",
    "\n",
    "In order to convert the dataset obtained from kaggle into a more usable format we will convert it into a SQLite database.\n",
    "\n",
    "#### First we developed the database schema to better understand our goal with this step\n",
    "\n",
    "The schema can be found in [this](movie_corpus_schema.sql) file.\n",
    "\n",
    "Consist in 6 tables:\n",
    " - Movie: contains the movie title, release year, IMDB rating and votes. (poster, revenue, runtime)\n",
    " - Character: contains character name, the movie it belongs to, its gender and credits position, that determine its relevance.\n",
    " - Genre: contains the genre name. Its linked to the movie through a pivot table called movie_genre.\n",
    " - Conversation: contains the ids of the caracters involved in the conversation and the id of the movie it belongs to.\n",
    " - Line: contains the text, the character that said it and the movie it belongs to. Also contains the conversation it was said in.\n",
    "\n",
    "#### After developing the schema we can create the database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: near line 44: in prepare, near \"ON\": syntax error (1)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# create database\n",
    "if os.path.exists('final.db'):\n",
    "    os.remove('final.db')\n",
    "\n",
    "os.system(\"cat movie_corpus_schema.sql | sqlite3 final.db\")\n",
    "\n",
    "connection = sqlite3.connect('final.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After this step we will start converting the csv data into database data\n",
    "\n",
    "Since we want to create a table with all the genres we need to parse it from the [movies](datasets/movie_titles_metadata.csv) format (e.g.: ['action' 'crime' 'drama' 'thriller'])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv('datasets/movie_titles_metadata.csv')\n",
    "\n",
    "# extract all genres from movies, the genres are stored as ['genre1' 'genre2' ...]\n",
    "genres = set()\n",
    "for genre in movies['genres']:\n",
    "    genres.update(genre.split(' '))\n",
    "\n",
    "# clean genres removing the ' and [ ]\n",
    "genres = [genre.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\") for genre in genres]\n",
    "# remove empty genres\n",
    "genres = [genre for genre in genres if genre != '']\n",
    "genres = set(genres)\n",
    "\n",
    "# transform genres into a list of tuples (id, name)\n",
    "genres = [(i + 1, genre) for i, genre in enumerate(genres)]\n",
    "\n",
    "# create a table for genre\n",
    "genres = pd.DataFrame(genres, columns=['id', 'name'])\n",
    "genres.to_sql('genre', connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the movie_genre pivot table\n",
    "\n",
    "Our goal is to populate this table with the movie and genre ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1871"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create movie id and genre id pivot table\n",
    "movie_genre = []\n",
    "for i, row in movies.iterrows():\n",
    "    for genre in row['genres'].split(' '):\n",
    "        genre = genre.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        if genre != '':\n",
    "            genre_id = genres[genres['name'] == genre]['id'].values[0]\n",
    "            movie_genre.append((row['id'], genre_id))\n",
    "        \n",
    "movie_genre = pd.DataFrame(movie_genre, columns=['movie_id', 'genre_id'])\n",
    "movie_genre.to_sql('movie_genre', connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populating movie table\n",
    "\n",
    "After fetching the genres information we can drop this column from the dataframe and finally insert the relevant information into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop movies genres column\n",
    "movies = movies.drop(columns=['genres'])\n",
    "movies = pd.DataFrame(movies, columns=[\"id\",\"title\",\"year\",\"imdb_rating\",\"imdb_votes\"])\n",
    "\n",
    "movies.to_sql('movie', connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate the characters table\n",
    "\n",
    "In this table the information available in the csv is all necessary, excluding the movie title. Since there are some characters with unknown gender or credits positions we will convert this cases to NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9035"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create characters table\n",
    "characters = pd.read_csv('./datasets/movie_characters_metadata.csv')\n",
    "characters = characters.drop(columns=[\"movie_title\"])\n",
    "\n",
    "# replace ? with null\n",
    "for i, character in characters.iterrows():\n",
    "    if character['gender'] == '?':\n",
    "        character['gender'] = None\n",
    "    if character['credit_pos'] == '?':\n",
    "        character['credit_pos'] = None\n",
    "\n",
    "\n",
    "characters.to_sql('character', connection, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate line and conversation tables\n",
    "\n",
    "To finish this database population we still need to populate these two tables. We need to convert the representation of conversations (e.g.: ['L271' 'L272' 'L273' 'L274' 'L275']) into foreign keys in the line table.\n",
    "\n",
    "We also realized that the lines include text formatting tags so we will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = pd.read_csv('./datasets/movie_conversations.csv')\n",
    "lines = pd.read_csv('./datasets/movie_lines.csv')\n",
    "lines.drop(columns=['character_name'], inplace=True)\n",
    "# add column conversation_id to lines with default null\n",
    "lines['conversation_id'] = None\n",
    "conversations['id'] = conversations.index + 1\n",
    "\n",
    "for i, line in lines.iterrows():\n",
    "    line['line_text'] = str(line['line_text']).replace(\"<u>\", \"\").replace(\"</u>\", \"\").replace(\"<i>\", \"\").replace(\"</i>\", \"\").replace(\"<b>\", \"\").replace(\"</b>\", \"\")\n",
    "\n",
    "\n",
    "for i, conversation in conversations.iterrows():\n",
    "    conversation_id = i + 1\n",
    "    lines_aux = []\n",
    "    for line in conversation['lines'].split(' '):\n",
    "        line = line.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        if line != '':\n",
    "            lines_aux.append(line)\n",
    "    for line in lines_aux:\n",
    "        lines.loc[lines['id'] == line, 'conversation_id'] = conversation_id\n",
    "\n",
    "\n",
    "lines.to_sql('line', connection, if_exists='append', index=False)\n",
    "conversations = conversations.drop(columns=['lines'])\n",
    "conversations.to_sql('conversation', connection, if_exists='append', index=False)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continued in [api fetching](api_test.ipynb) notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
